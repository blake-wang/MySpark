# 上线配置
## 数据库配置
spark.local=false
jdbc.url=jdbc:mysql://10.45.191.46:3306/xiaopeng2_bi?user=hadoop&password=hadoopmaster2016abt&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false
jdbc.user=hadoop
jdbc.pwd=hadoopmaster2016abt
jdbc.xiaopeng2.url=jdbc:mysql://10.116.123.113:3306/xiaopeng2?user=hadoop&password=hadoopmaster2016abt&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false
jdbc.xiaopeng2.user=hadoop
jdbc.xiaopeng2.pwd=hadoopmaster2016abt
jdbc.xiaopeng2bihip.url=jdbc:mysql://10.24.167.208:3306/xiaopeng2_bi?user=hadoop&password=hadoopmaster2016abt&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false
jdbc.xiaopeng2fx.url=jdbc:mysql://10.116.123.113:3306/xiaopeng2_faxing?user=hadoop&password=hadoopmaster2016abt&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false
jdbc.xiaopeng2fx.user=hadoop
jdbc.xiaopeng2fx.pwd=hadoopmaster2016abt
jdbc.driver=com.mysql.jdbc.Driver


# kafka 配置
kafka.metadata.broker.list=hadoopmaster:9092,hadoopslave1:9092,hadoopslave2:9092

kafka.topics.account=login,regi,order
spark.checkpoint.account=/home/hduser/spark/spark-1.6.1/checkpointdir/centurioncardaccount

kafka.topics.apppoints=order,points
spark.checkpoint.apppoints=/home/hduser/spark/spark-1.6.1/checkpointdir/apppoints

kafka.topics.kpi=regi,order,login,active,pubgame,channel,request,thirddata
spark.checkpoint.kpi=file:///home/hduser/spark/spark-1.6.1/checkpointdir/checkpointkpi

kafka.topics.backend=member,regi,order,binduid,login
spark.checkpoint.backend=/home/hduser/spark/spark-1.6.1/checkpointdir/backend


#kafka.topics.member=member,regi,order,binduid
#spark.checkpoint.member=/home/hduser/spark/spark-1.6.1/checkpointdir/member


topicsApp=order,appdownload,login,appinstall
App2_2=file:///home/hduser/spark/spark-1.6.1/checkpointdir/App2_2

#离线任务 数据目录配置
gamepublish.offline.regi=hdfs://hadoopmaster:9000/user/hive/warehouse/yyft.db/regi/*
gamepublish.offline.order=hdfs://hadoopmaster:9000/user/hive/warehouse/yyft.db/order/*
gamepublish.offline.thirddata=hdfs://hadoopmaster:9000/user/hive/warehouse/yyft.db/thirddata/*

fxdim.parquet=hdfs://hadoopmaster:9000/tmp/hive/fxdim.parquet

# spark 参数配置
coalesce.partitioin.num=40
spark.sql.shuffle.partitions=40
spark.memory.storageFraction=0.2

#redis相关配置
redis.host=10.46.133.54
redis.port=6379
redis.max.idle=50
redis.max.total=1000
redis.max.wait.millis=10000

#web交互的模式
web.url.mode=product

#kafka regi日志缓存一批目录地址
regi_log_cache=hdfs://hadoopmaster:9000/home/hduser/spark/spark-1.6.1/checkpointdir/thirddata_regi_log_cache
